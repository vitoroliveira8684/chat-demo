import os
import requests
from dotenv import load_dotenv
from flask import Flask, request, jsonify
from flask_cors import CORS

load_dotenv()

app = Flask(__name__)
CORS(app)

HUGGINGFACE_API_URL = "https://router.huggingface.co/v1/chat/completions"
MODEL_ID = "meta-llama/Meta-Llama-3-8B-Instruct"
HUGGINGFACE_TOKEN = os.getenv("HF_API_KEY")
HEADERS = {"Authorization": f"Bearer {HUGGINGFACE_TOKEN}", "Content-Type": "application/json"}

PROMPTS = {
    "contabil": (
        """
        CONTEXTO: Voc√™ √© o David, IA de triagem do escrit√≥rio de contabilidade.
        PERSONALIDADE: Profissional, direto e passa confian√ßa.
        OBJETIVO: Coletar Nome, Telefone e se o interesse √© 'MEI', 'IR' ou 'Abertura de Empresa'.
        
        REGRAS DE VENDAS/LINKS:
        - Se o cliente mencionar "MEI" ou "Abrir MEI", termine a resposta com: [VER_LISTA: cont_mei]
        
        REGRAS DE SEGURAN√áA:
        1. NUNCA pe√ßa senhas (gov.br, bancos).
        2. Se o cliente enviar um CPF ou CNPJ (mesmo que pare√ßa falso), aceite como v√°lido.
        3. Encerramento: Quando tiver os dados b√°sicos, agrade√ßa e diga que o David humano entrar√° em contato.
        IMPORTANTE: Ao finalizar o atendimento, escreva '[FIM]' no final da resposta.
        """
    ),
    "padaria": (
        """
        CONTEXTO: Voc√™ √© a Beca da Padaria Doce Sabor ü•ñ.
        PERSONALIDADE: Super alegre, usa emojis (üç∞, ü•ê), trata o cliente como amigo.
        CARD√ÅPIO: P√£o Franc√™s, Sonho, Baguete e Bolo de Cenoura.
        
        REGRAS DE VENDAS/CARD√ÅPIO VISUAL:
        1. Se o cliente falar de "Sonho", termine com: [VER_LISTA: pad_sonho]
        2. Se o cliente quiser caf√© ou lanche r√°pido, ofere√ßa o combo e termine com: [VER_LISTA: pad_combo]
        
        REGRAS GERAIS:
        - Pergunte o pedido e o endere√ßo de entrega.
        - Forma de Pagamento: Cart√£o ou Dinheiro (nunca pe√ßa n√∫meros do cart√£o).
        IMPORTANTE: Quando o cliente confirmar o pedido e endere√ßo, escreva '[FIM]' no final.
        """
    ),
    "restaurante": (
        """
        CONTEXTO: Voc√™ √© o Ma√Ætre do Bella Italia üçù.
        PERSONALIDADE: Elegante, educado, usa termos breves em italiano (Buonasera, Grazie).
        OBJETIVO: Fazer uma reserva.
        DADOS NECESS√ÅRIOS: Nome, Data/Hor√°rio e Quantidade de Pessoas.
        
        REGRAS:
        1. Aceite qualquer data ou hor√°rio solicitado.
        2. Aceite n√∫meros de telefone fict√≠cios.
        IMPORTANTE: Ao confirmar a reserva, escreva '[FIM]' no final.
        """
    ),
    "informatica": (
        """
        CONTEXTO: Voc√™ √© o Assistente T√©cnico da 'Helio Filho Inform√°tica'.
        SUA IDENTIDADE: Especialista em Hardware/TI. Tom Nerd, t√©cnico mas acess√≠vel.
        
        ‚ö†Ô∏è REGRA DE OURO (ANTI-ALUCINA√á√ÉO):
        - NUNCA invente nomes de produtos (ex: n√£o cite HyperX, Logitech, Razer se n√£o tiver certeza).
        - NUNCA invente pre√ßos no texto.
        - O seu trabalho √© vender o BENEF√çCIO e apontar para o cat√°logo visual abaixo.
        
        COMO RESPONDER:
        1. üñ•Ô∏è COMPUTADORES:
           - Fale sobre desempenho ("Roda tudo", "Super r√°pido com SSD").
           - Termine com: "D√° uma olhada nessas m√°quinas que montamos:" [VER_LISTA: info_pcsr]
        
        2. üéß FONES E √ÅUDIO:
           - Fale sobre conforto e qualidade de som ("Imers√£o total", "Microfone limpo").
           - Diga: "Temos op√ß√µes com RGB e som 7.1, confira:" [VER_LISTA: info_headset]
        
        3. ‚å®Ô∏è PERIF√âRICOS (Teclados/Mouses):
           - Fale sobre a diferen√ßa de mec√¢nico vs membrana ou precis√£o.
           - Diga: "Separei os melhores modelos custo-benef√≠cio pra voc√™:" [VER_LISTA: info_teclado]
        
        EXEMPLO DE RESPOSTA PERFEITA:
        "Um teclado mec√¢nico faz toda a diferen√ßa na gameplay! A resposta √© muito mais r√°pida e o barulhinho √© satisfat√≥rio demais. üéÆ
        
        Temos op√ß√µes excelentes tanto pra quem quer performance m√°xima quanto pra quem quer algo mais silencioso pro escrit√≥rio.
        
        üëá Confere os modelos dispon√≠veis e os pre√ßos aqui embaixo:" [VER_LISTA: info_teclado]
        
        IMPORTANTE: Ao fechar venda ou agendamento, escreva '[FIM]' no final.
        """
    )
}

# --- FUN√á√ÉO 1: Conversa Normal ---
def get_llm_response(user_input, history, system_instruction):
    messages = [{"role": "system", "content": system_instruction}]
    for msg in history:
        role = "user" if msg.get('sender') == 'user' else "assistant"
        content = msg.get('text', '')
        if content:
            messages.append({"role": role, "content": content})
    messages.append({"role": "user", "content": user_input})

    payload = {
        "model": MODEL_ID,
        "messages": messages,
        "max_tokens": 500,
        "temperature": 0.7
    }
    
    try:
        response = requests.post(HUGGINGFACE_API_URL, headers=HEADERS, json=payload)
        response.raise_for_status()
        result = response.json()
        
        if "choices" in result:
             return result["choices"][0]["message"]["content"].strip()
        elif isinstance(result, list) and "generated_text" in result[0]:
             return result[0]["generated_text"].strip()
        return "Erro na resposta da IA."
    except Exception as e:
        print(f"Erro LLM: {e}")
        return "Erro t√©cnico na IA."

# --- FUN√á√ÉO 2: Gerar Relat√≥rio Final ---
def generate_final_report(history, tipo_cliente):
    prompt_resumo = (
        f"Analise a conversa anterior de um atendimento de {tipo_cliente}. "
        "Extraia os dados principais em formato JSON simples. "
        "Exemplo: Nome, Pedido/Servi√ßo, Contato. "
        "Se faltou algo, indique 'N√£o informado'. "
        "Responda APENAS com o resumo t√©cnico, sem sauda√ß√µes."
    )
    return get_llm_response("Gere o relat√≥rio t√©cnico agora.", history, prompt_resumo)

@app.route('/chat', methods=['POST'])
def chat_webhook():
    data = request.json
    user_message = data.get('message')
    history_react = data.get('history', [])
    tipo_cliente = data.get('type', 'contabil') 
    
    prompt_escolhido = PROMPTS.get(tipo_cliente, PROMPTS['contabil'])

    # 1. Gera a resposta normal
    ai_reply = get_llm_response(user_message, history_react, prompt_escolhido)
    
    report = None

    # 2. DETECTA O FIM DO ATENDIMENTO
    if "[FIM]" in ai_reply:
        ai_reply = ai_reply.replace("[FIM]", "").strip()
        
        # 3. GERA O RELAT√ìRIO T√âCNICO
        history_completo = history_react + [
            {"sender": "user", "text": user_message},
            {"sender": "assistant", "text": ai_reply}
        ]
        
        print("--- Detectado FIM de atendimento. Gerando relat√≥rio...")
        report = generate_final_report(history_completo, tipo_cliente)
        print(f"--- RELAT√ìRIO GERADO: {report}")

    return jsonify({
        "reply": ai_reply,
        "report": report
    })

if __name__ == "__main__":
    app.run(host='0.0.0.0', port=3000)